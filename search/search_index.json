{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"HTTPX Retries","text":"<p>A retry layer for HTTPX.</p> <p>HTTPX Retries implements request retry for HTTPX.</p> <p>It's very common to deal with flaky and unreliable APIs. When requests fail, your program needs to be able to retry them.</p> <p>Install HTTPX Retries using pip:</p> <pre><code>pip install httpx-retries\n</code></pre> <p>To get started, add the transport to your client:</p> <pre><code>import httpx\nfrom httpx_retries import RetryTransport\n\nwith httpx.Client(transport=RetryTransport()) as client:\n    response = client.get(\"https://example.com\")\n</code></pre> <p>Async usage is just as straightforward.</p> <pre><code>async with httpx.AsyncClient(transport=RetryTransport()) as client:\n    response = await client.get(\"https://example.com\")\n</code></pre> <p>If you want to use a specific retry strategy, provide a Retry configuration:</p> <pre><code>from httpx_retries import Retry\n\nretry = Retry(total=5, backoff_factor=0.5)\ntransport = RetryTransport(retry=retry)\n\nwith httpx.Client(transport=transport) as client:\n    response = client.get(\"https://example.com\")\n</code></pre>"},{"location":"#features","title":"Features","text":"<p>HTTPX Retries builds on the patterns users expect from <code>urllib</code> and <code>requests</code>. The typical approach has been to use urllib3's Retry utility to configure a retry policy. The equivalent code to match the above example using requests is:</p> <pre><code>from requests.adapters import HTTPAdapter\nfrom urllib3.util.retry import Retry\n\nretry = Retry(total=5, backoff_factor=0.5)\nadapter = HTTPAdapter(max_retries=retry)\n\nwith requests.Session() as session:\n    session.mount(\"http://\", adapter)\n    session.mount(\"https://\", adapter)\n    response = session.get(\"https://example.com\")\n</code></pre> <p>To reduce boilerplate, this package includes a transport that works with both sync and async HTTPX Clients, with sensible defaults for simple use cases.</p> <p>HTTPX adds support for asynchronous requests, and this package includes a new retry utility that can handle this behaviour (Retry). To make it easy to migrate, the API surface is almost identical to <code>Retry</code> from urllib3, with a few main differences:</p> <ul> <li><code>total</code> is the only parameter used to configure the number of retries.</li> <li>asleep is an async implementation of sleep.</li> <li>backoff_strategy can be overridden to customize backoff behavior.</li> <li>Some options that are not strictly retry-related are not included (<code>raise_on_status</code>, <code>raise_on_redirect</code>)</li> </ul> <p>Note</p> <p>For more information, visit the API reference.</p>"},{"location":"#acknowledgements","title":"Acknowledgements","text":"<p>This package builds on the great work done on HTTPX, urllib3 and requests.</p>"},{"location":"api/","title":"API","text":""},{"location":"api/#httpx_retries.RetryTransport","title":"<code>RetryTransport</code>","text":"<p>               Bases: <code>BaseTransport</code>, <code>AsyncBaseTransport</code></p> <p>A transport that automatically retries requests.</p> <pre><code>with httpx.Client(transport=RetryTransport()) as client:\n    response = client.get(\"https://example.com\")\n\nasync with httpx.AsyncClient(transport=RetryTransport()) as client:\n    response = await client.get(\"https://example.com\")\n</code></pre> <p>If you want to use a specific retry strategy, provide a Retry configuration:</p> <pre><code>retry = Retry(total=5, backoff_factor=0.5)\ntransport = RetryTransport(retry=retry)\n\nwith httpx.Client(transport=transport) as client:\n    response = client.get(\"https://example.com\")\n</code></pre> <p>By default, the implementation will create a sync and async transport internally, and use whichever is appropriate for the request. If you want to configure your own transport, provide it to the <code>transport</code> argument:</p> <pre><code>transport = RetryTransport(transport=httpx.HTTPTransport(local_address=\"0.0.0.0\"))\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>transport</code> <code>Optional[Union[BaseTransport, AsyncBaseTransport]]</code> <p>Optional transport to wrap. If not provided, async and sync transports are created internally.</p> <code>None</code> <code>retry</code> <code>Optional[Retry]</code> <p>The retry configuration.</p> <code>None</code> Source code in <code>httpx_retries/transport.py</code> <pre><code>class RetryTransport(httpx.BaseTransport, httpx.AsyncBaseTransport):\n    \"\"\"\n    A transport that automatically retries requests.\n\n    ```python\n    with httpx.Client(transport=RetryTransport()) as client:\n        response = client.get(\"https://example.com\")\n\n    async with httpx.AsyncClient(transport=RetryTransport()) as client:\n        response = await client.get(\"https://example.com\")\n    ```\n\n    If you want to use a specific retry strategy, provide a [Retry][httpx_retries.Retry] configuration:\n\n    ```python\n    retry = Retry(total=5, backoff_factor=0.5)\n    transport = RetryTransport(retry=retry)\n\n    with httpx.Client(transport=transport) as client:\n        response = client.get(\"https://example.com\")\n    ```\n\n    By default, the implementation will create a sync and async transport internally, and use whichever is appropriate\n    for the request. If you want to configure your own transport, provide it to the `transport` argument:\n\n    ```python\n    transport = RetryTransport(transport=httpx.HTTPTransport(local_address=\"0.0.0.0\"))\n    ```\n\n    Args:\n        transport: Optional transport to wrap. If not provided, async and sync transports are created internally.\n        retry: The retry configuration.\n    \"\"\"\n\n    def __init__(\n        self,\n        transport: Optional[Union[httpx.BaseTransport, httpx.AsyncBaseTransport]] = None,\n        retry: Optional[Retry] = None,\n    ) -&gt; None:\n        self.retry = retry or Retry()\n\n        if transport is not None:\n            self._sync_transport = transport if isinstance(transport, httpx.BaseTransport) else None\n            self._async_transport = transport if isinstance(transport, httpx.AsyncBaseTransport) else None\n        else:\n            self._sync_transport = httpx.HTTPTransport()\n            self._async_transport = httpx.AsyncHTTPTransport()\n\n    def close(self) -&gt; None:\n        \"\"\"\n        Closes this transport.\n        \"\"\"\n        if self._sync_transport is not None:\n            self._sync_transport.close()\n\n    async def aclose(self) -&gt; None:\n        \"\"\"\n        Closes this transport.\n        \"\"\"\n        if self._async_transport is not None:\n            await self._async_transport.aclose()\n\n    def handle_request(self, request: httpx.Request) -&gt; httpx.Response:\n        \"\"\"\n        Sends an HTTP request, possibly with retries.\n\n        Args:\n            request (httpx.Request): The request to send.\n\n        Returns:\n            The final response.\n        \"\"\"\n        if self._sync_transport is None:\n            raise RuntimeError(\"Synchronous request received but no sync transport available\")\n\n        logger.debug(\"handle_request started request=%s\", request)\n\n        if self.retry.is_retryable_method(request.method):\n            send_method = partial(self._sync_transport.handle_request)\n            response = self._retry_operation(request, send_method)\n        else:\n            response = self._sync_transport.handle_request(request)\n\n        logger.debug(\"handle_request finished request=%s response=%s\", request, response)\n\n        return response\n\n    async def handle_async_request(self, request: httpx.Request) -&gt; httpx.Response:\n        \"\"\"Sends an HTTP request, possibly with retries.\n\n        Args:\n            request: The request to perform.\n\n        Returns:\n            The final response.\n        \"\"\"\n        if self._async_transport is None:\n            raise RuntimeError(\"Async request received but no async transport available\")\n\n        logger.debug(\"handle_async_request started request=%s\", request)\n\n        if self.retry.is_retryable_method(request.method):\n            send_method = partial(self._async_transport.handle_async_request)\n            response = await self._retry_operation_async(request, send_method)\n        else:\n            response = await self._async_transport.handle_async_request(request)\n\n        logger.debug(\"handle_async_request finished request=%s response=%s\", request, response)\n\n        return response\n\n    def _retry_operation(\n        self,\n        request: httpx.Request,\n        send_method: Callable[..., httpx.Response],\n    ) -&gt; httpx.Response:\n        retry = self.retry\n        response: Union[httpx.Response, Exception, None] = None\n\n        while True:\n            if response is not None:\n                if isinstance(response, httpx.Response):\n                    response.close()\n\n                logger.debug(\"_retry_operation retrying request=%s response=%s retry=%s\", request, response, retry)\n                retry = retry.increment()\n                retry.sleep(response)\n            try:\n                response = send_method(request)\n            except Exception as e:\n                if retry.is_exhausted() or not retry.is_retryable_exception(e):\n                    raise\n\n                response = e\n                continue\n\n            if retry.is_exhausted() or not retry.is_retryable_status_code(response.status_code):\n                return response\n\n    async def _retry_operation_async(\n        self,\n        request: httpx.Request,\n        send_method: Callable[..., Coroutine[Any, Any, httpx.Response]],\n    ) -&gt; httpx.Response:\n        retry = self.retry\n        response: Union[httpx.Response, Exception, None] = None\n\n        while True:\n            if response is not None:\n                if isinstance(response, httpx.Response):\n                    await response.aclose()\n\n                logger.debug(\n                    \"_retry_operation_async retrying request=%s response=%s retry=%s\", request, response, retry\n                )\n                retry = retry.increment()\n                await retry.asleep(response)\n            try:\n                response = await send_method(request)\n            except Exception as e:\n                if retry.is_exhausted() or not retry.is_retryable_exception(e):\n                    raise\n\n                response = e\n                continue\n\n            if retry.is_exhausted() or not retry.is_retryable_status_code(response.status_code):\n                return response\n</code></pre>"},{"location":"api/#httpx_retries.RetryTransport.aclose","title":"<code>aclose()</code>  <code>async</code>","text":"<p>Closes this transport.</p> Source code in <code>httpx_retries/transport.py</code> <pre><code>async def aclose(self) -&gt; None:\n    \"\"\"\n    Closes this transport.\n    \"\"\"\n    if self._async_transport is not None:\n        await self._async_transport.aclose()\n</code></pre>"},{"location":"api/#httpx_retries.RetryTransport.close","title":"<code>close()</code>","text":"<p>Closes this transport.</p> Source code in <code>httpx_retries/transport.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"\n    Closes this transport.\n    \"\"\"\n    if self._sync_transport is not None:\n        self._sync_transport.close()\n</code></pre>"},{"location":"api/#httpx_retries.RetryTransport.handle_async_request","title":"<code>handle_async_request(request)</code>  <code>async</code>","text":"<p>Sends an HTTP request, possibly with retries.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>Request</code> <p>The request to perform.</p> required <p>Returns:</p> Type Description <code>Response</code> <p>The final response.</p> Source code in <code>httpx_retries/transport.py</code> <pre><code>async def handle_async_request(self, request: httpx.Request) -&gt; httpx.Response:\n    \"\"\"Sends an HTTP request, possibly with retries.\n\n    Args:\n        request: The request to perform.\n\n    Returns:\n        The final response.\n    \"\"\"\n    if self._async_transport is None:\n        raise RuntimeError(\"Async request received but no async transport available\")\n\n    logger.debug(\"handle_async_request started request=%s\", request)\n\n    if self.retry.is_retryable_method(request.method):\n        send_method = partial(self._async_transport.handle_async_request)\n        response = await self._retry_operation_async(request, send_method)\n    else:\n        response = await self._async_transport.handle_async_request(request)\n\n    logger.debug(\"handle_async_request finished request=%s response=%s\", request, response)\n\n    return response\n</code></pre>"},{"location":"api/#httpx_retries.RetryTransport.handle_request","title":"<code>handle_request(request)</code>","text":"<p>Sends an HTTP request, possibly with retries.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>Request</code> <p>The request to send.</p> required <p>Returns:</p> Type Description <code>Response</code> <p>The final response.</p> Source code in <code>httpx_retries/transport.py</code> <pre><code>def handle_request(self, request: httpx.Request) -&gt; httpx.Response:\n    \"\"\"\n    Sends an HTTP request, possibly with retries.\n\n    Args:\n        request (httpx.Request): The request to send.\n\n    Returns:\n        The final response.\n    \"\"\"\n    if self._sync_transport is None:\n        raise RuntimeError(\"Synchronous request received but no sync transport available\")\n\n    logger.debug(\"handle_request started request=%s\", request)\n\n    if self.retry.is_retryable_method(request.method):\n        send_method = partial(self._sync_transport.handle_request)\n        response = self._retry_operation(request, send_method)\n    else:\n        response = self._sync_transport.handle_request(request)\n\n    logger.debug(\"handle_request finished request=%s response=%s\", request, response)\n\n    return response\n</code></pre>"},{"location":"api/#httpx_retries.Retry","title":"<code>Retry</code>","text":"<p>A class to encapsulate retry logic and configuration.</p> <p>Each retry attempt will create a new Retry object with updated values, so they can safely be reused.</p> <p>If <code>backoff_factor</code> is set, it will use an exponential backoff with configurable jitter.</p> <p>For complex use cases, you can override the <code>backoff_strategy</code> method.</p> <p>Parameters:</p> Name Type Description Default <code>total</code> <code>int</code> <p>The maximum number of times to retry a request before giving up.</p> <code>10</code> <code>max_backoff_wait</code> <code>float</code> <p>The maximum time in seconds to wait between retries.</p> <code>120.0</code> <code>backoff_factor</code> <code>float</code> <p>The factor by which the wait time increases with each retry attempt.</p> <code>0.0</code> <code>respect_retry_after_header</code> <code>bool</code> <p>Whether to respect the Retry-After header in HTTP responses when deciding how long to wait before retrying.</p> <code>True</code> <code>allowed_methods</code> <code>Iterable[HTTPMethod, str]</code> <p>The HTTP methods that can be retried. Defaults to [\"HEAD\", \"GET\", \"PUT\", \"DELETE\", \"OPTIONS\", \"TRACE\"].</p> <code>None</code> <code>status_forcelist</code> <code>Iterable[HTTPStatus, int]</code> <p>The HTTP status codes that can be retried. Defaults to [429, 502, 503, 504].</p> <code>None</code> <code>retry_on_exceptions</code> <code>Iterable[Type[HTTPError]]</code> <p>The HTTP exceptions that can be retried. Defaults to [httpx.TimeoutException, httpx.NetworkError, httpx.RemoteProtocolError].</p> <code>None</code> <code>backoff_jitter</code> <code>float</code> <p>The amount of jitter to add to the backoff time, between 0 and 1. Defaults to 1 (full jitter).</p> <code>1.0</code> <code>attempts_made</code> <code>int</code> <p>The number of retry attempts already made.</p> <code>0</code> Source code in <code>httpx_retries/retry.py</code> <pre><code>class Retry:\n    \"\"\"\n    A class to encapsulate retry logic and configuration.\n\n    Each retry attempt will create a new [Retry][httpx_retries.Retry] object with updated values,\n    so they can safely be reused.\n\n    If `backoff_factor` is set, it will use an exponential backoff with configurable jitter.\n\n    For complex use cases, you can override the `backoff_strategy` method.\n\n    Args:\n        total (int, optional): The maximum number of times to retry a request before giving up.\n        max_backoff_wait (float, optional): The maximum time in seconds to wait between retries.\n        backoff_factor (float, optional): The factor by which the wait time increases with each retry attempt.\n        respect_retry_after_header (bool, optional): Whether to respect the Retry-After header in HTTP responses\n            when deciding how long to wait before retrying.\n        allowed_methods (Iterable[http.HTTPMethod, str], optional): The HTTP methods that can be retried. Defaults to\n            [\"HEAD\", \"GET\", \"PUT\", \"DELETE\", \"OPTIONS\", \"TRACE\"].\n        status_forcelist (Iterable[http.HTTPStatus, int], optional): The HTTP status codes that can be retried.\n            Defaults to [429, 502, 503, 504].\n        retry_on_exceptions (Iterable[Type[httpx.HTTPError]], optional): The HTTP exceptions that can be retried.\n            Defaults to [httpx.TimeoutException, httpx.NetworkError, httpx.RemoteProtocolError].\n        backoff_jitter (float, optional): The amount of jitter to add to the backoff time, between 0 and 1.\n            Defaults to 1 (full jitter).\n        attempts_made (int, optional): The number of retry attempts already made.\n    \"\"\"\n\n    RETRYABLE_METHODS: Final[frozenset[HTTPMethod]] = frozenset(\n        [HTTPMethod.HEAD, HTTPMethod.GET, HTTPMethod.PUT, HTTPMethod.DELETE, HTTPMethod.OPTIONS, HTTPMethod.TRACE]\n    )\n    RETRYABLE_STATUS_CODES: Final[frozenset[HTTPStatus]] = frozenset(\n        [\n            HTTPStatus.TOO_MANY_REQUESTS,\n            HTTPStatus.BAD_GATEWAY,\n            HTTPStatus.SERVICE_UNAVAILABLE,\n            HTTPStatus.GATEWAY_TIMEOUT,\n        ]\n    )\n    RETRYABLE_EXCEPTIONS: Final[Tuple[Type[Exception], ...]] = (\n        httpx.TimeoutException,\n        httpx.NetworkError,\n        httpx.RemoteProtocolError,\n    )\n\n    def __init__(\n        self,\n        total: int = 10,\n        allowed_methods: Optional[Iterable[Union[HTTPMethod, str]]] = None,\n        status_forcelist: Optional[Iterable[Union[HTTPStatus, int]]] = None,\n        retry_on_exceptions: Optional[Iterable[Type[Exception]]] = None,\n        backoff_factor: float = 0.0,\n        respect_retry_after_header: bool = True,\n        max_backoff_wait: float = 120.0,\n        backoff_jitter: float = 1.0,\n        attempts_made: int = 0,\n    ) -&gt; None:\n        \"\"\"Initialize a new Retry instance.\"\"\"\n        if total &lt; 0:\n            raise ValueError(\"total must be non-negative\")\n        if backoff_factor &lt; 0:\n            raise ValueError(\"backoff_factor must be non-negative\")\n        if max_backoff_wait &lt;= 0:\n            raise ValueError(\"max_backoff_wait must be positive\")\n        if not 0 &lt;= backoff_jitter &lt;= 1:\n            raise ValueError(\"backoff_jitter must be between 0 and 1\")\n        if attempts_made &lt; 0:\n            raise ValueError(\"attempts_made must be non-negative\")\n\n        self.total = total\n        self.backoff_factor = backoff_factor\n        self.respect_retry_after_header = respect_retry_after_header\n        self.max_backoff_wait = max_backoff_wait\n        self.backoff_jitter = backoff_jitter\n        self.attempts_made = attempts_made\n\n        self.allowed_methods = frozenset(\n            HTTPMethod(method.upper()) for method in (allowed_methods or self.RETRYABLE_METHODS)\n        )\n        self.status_forcelist = frozenset((status_forcelist or self.RETRYABLE_STATUS_CODES))\n        self.retryable_exceptions = (\n            self.RETRYABLE_EXCEPTIONS if retry_on_exceptions is None else tuple(retry_on_exceptions)\n        )\n\n    def is_retryable_method(self, method: str) -&gt; bool:\n        \"\"\"Check if a method is retryable.\"\"\"\n        return HTTPMethod(method.upper()) in self.allowed_methods\n\n    def is_retryable_status_code(self, status_code: int) -&gt; bool:\n        \"\"\"Check if a status code is retryable.\"\"\"\n        return status_code in self.status_forcelist\n\n    def is_retryable_exception(self, exception: Exception) -&gt; bool:\n        \"\"\"Check if an exception is retryable.\"\"\"\n        return isinstance(exception, self.retryable_exceptions)\n\n    def is_retry(self, method: str, status_code: int, has_retry_after: bool) -&gt; bool:\n        \"\"\"\n        Check if a method and status code are retryable.\n\n        This functions identically to urllib3's `Retry.is_retry` method.\n        \"\"\"\n        return (\n            self.total &gt; 0\n            and self.is_retryable_method(method)\n            and self.is_retryable_status_code(status_code)\n            and not has_retry_after\n        )\n\n    def is_exhausted(self) -&gt; bool:\n        \"\"\"Check if the retry attempts have been exhausted.\"\"\"\n        return self.attempts_made &gt;= self.total\n\n    def parse_retry_after(self, retry_after: str) -&gt; float:\n        \"\"\"\n        Parse the Retry-After header.\n\n        Args:\n            retry_after: The Retry-After header value.\n\n        Returns:\n            The number of seconds to wait before retrying.\n\n        Raises:\n            ValueError: If the Retry-After header is not a valid number or HTTP date.\n        \"\"\"\n        retry_after = retry_after.strip()\n        if retry_after.isdigit():\n            return float(retry_after)\n\n        try:\n            parsed_date = parsedate_to_datetime(retry_after)\n            if parsed_date.tzinfo is None:\n                parsed_date = parsed_date.replace(tzinfo=datetime.timezone.utc)\n\n            diff = (parsed_date - datetime.datetime.now(datetime.timezone.utc)).total_seconds()\n            return max(0.0, diff)\n        except (TypeError, ValueError):\n            raise ValueError(f\"Invalid Retry-After header: {retry_after}\")\n\n    def backoff_strategy(self) -&gt; float:\n        \"\"\"\n        Calculate the backoff time based on the number of attempts.\n\n        For complex use cases, you can override this method to implement a custom backoff strategy.\n\n        ```python\n        class CustomRetry(Retry):\n            def backoff_strategy(self) -&gt; float:\n                if self.attempts_made == 3:\n                    return 1.0\n\n                return super().backoff_strategy()\n        ```\n\n        Returns:\n            The calculated backoff time in seconds, capped by max_backoff_wait.\n        \"\"\"\n        if self.backoff_factor == 0:\n            return 0.0\n\n        # Calculate exponential backoff\n        backoff: float = self.backoff_factor * (2**self.attempts_made)\n\n        # Apply jitter if configured\n        if self.backoff_jitter &gt; 0:\n            backoff *= random.uniform(1 - self.backoff_jitter, 1)\n\n        return min(backoff, self.max_backoff_wait)\n\n    def _calculate_sleep(self, headers: Union[httpx.Headers, Mapping[str, str]]) -&gt; float:\n        \"\"\"Calculate the sleep duration based on headers and backoff strategy.\"\"\"\n        # Check Retry-After header first if enabled\n        if self.respect_retry_after_header:\n            retry_after = headers.get(\"Retry-After\", \"\").strip()\n            if retry_after:\n                try:\n                    retry_after_sleep = min(self.parse_retry_after(retry_after), self.max_backoff_wait)\n                    if retry_after_sleep &gt; 0:\n                        return retry_after_sleep\n                except ValueError:\n                    logger.warning(\"Retry-After header is not a valid HTTP date: %s\", retry_after)\n\n        # Fall back to backoff strategy\n        return self.backoff_strategy() if self.attempts_made &gt; 0 else 0.0\n\n    def sleep(self, response: Union[httpx.Response, Exception]) -&gt; None:\n        \"\"\"\n        Sleep between retry attempts using the calculated duration.\n\n        This method will respect a server\u2019s `Retry-After` response header and sleep the duration\n        of the time requested. If that is not present, it will use an exponential backoff. By default,\n        the backoff factor is 0 and this method will return immediately.\n        \"\"\"\n        time_to_sleep = self._calculate_sleep(response.headers if isinstance(response, httpx.Response) else {})\n        logger.debug(\"sleep seconds=%s\", time_to_sleep)\n        time.sleep(time_to_sleep)\n\n    async def asleep(self, response: Union[httpx.Response, Exception]) -&gt; None:\n        \"\"\"\n        Sleep between retry attempts asynchronously using the calculated duration.\n\n        This method will respect a server\u2019s `Retry-After` response header and sleep the duration\n        of the time requested. If that is not present, it will use an exponential backoff. By default,\n        the backoff factor is 0 and this method will return immediately.\n        \"\"\"\n        time_to_sleep = self._calculate_sleep(response.headers if isinstance(response, httpx.Response) else {})\n        logger.debug(\"asleep seconds=%s\", time_to_sleep)\n        await asyncio.sleep(time_to_sleep)\n\n    def increment(self) -&gt; \"Retry\":\n        \"\"\"Return a new Retry instance with the attempt count incremented.\"\"\"\n        logger.debug(\"increment retry=%s new_attempts_made=%s\", self, self.attempts_made + 1)\n        return self.__class__(\n            total=self.total,\n            max_backoff_wait=self.max_backoff_wait,\n            backoff_factor=self.backoff_factor,\n            respect_retry_after_header=self.respect_retry_after_header,\n            allowed_methods=self.allowed_methods,\n            status_forcelist=self.status_forcelist,\n            retry_on_exceptions=self.retryable_exceptions,\n            backoff_jitter=self.backoff_jitter,\n            attempts_made=self.attempts_made + 1,\n        )\n\n    def __repr__(self) -&gt; str:\n        return f\"&lt;Retry(total={self.total}, attempts_made={self.attempts_made})&gt;\"\n</code></pre>"},{"location":"api/#httpx_retries.Retry.asleep","title":"<code>asleep(response)</code>  <code>async</code>","text":"<p>Sleep between retry attempts asynchronously using the calculated duration.</p> <p>This method will respect a server\u2019s <code>Retry-After</code> response header and sleep the duration of the time requested. If that is not present, it will use an exponential backoff. By default, the backoff factor is 0 and this method will return immediately.</p> Source code in <code>httpx_retries/retry.py</code> <pre><code>async def asleep(self, response: Union[httpx.Response, Exception]) -&gt; None:\n    \"\"\"\n    Sleep between retry attempts asynchronously using the calculated duration.\n\n    This method will respect a server\u2019s `Retry-After` response header and sleep the duration\n    of the time requested. If that is not present, it will use an exponential backoff. By default,\n    the backoff factor is 0 and this method will return immediately.\n    \"\"\"\n    time_to_sleep = self._calculate_sleep(response.headers if isinstance(response, httpx.Response) else {})\n    logger.debug(\"asleep seconds=%s\", time_to_sleep)\n    await asyncio.sleep(time_to_sleep)\n</code></pre>"},{"location":"api/#httpx_retries.Retry.backoff_strategy","title":"<code>backoff_strategy()</code>","text":"<p>Calculate the backoff time based on the number of attempts.</p> <p>For complex use cases, you can override this method to implement a custom backoff strategy.</p> <pre><code>class CustomRetry(Retry):\n    def backoff_strategy(self) -&gt; float:\n        if self.attempts_made == 3:\n            return 1.0\n\n        return super().backoff_strategy()\n</code></pre> <p>Returns:</p> Type Description <code>float</code> <p>The calculated backoff time in seconds, capped by max_backoff_wait.</p> Source code in <code>httpx_retries/retry.py</code> <pre><code>def backoff_strategy(self) -&gt; float:\n    \"\"\"\n    Calculate the backoff time based on the number of attempts.\n\n    For complex use cases, you can override this method to implement a custom backoff strategy.\n\n    ```python\n    class CustomRetry(Retry):\n        def backoff_strategy(self) -&gt; float:\n            if self.attempts_made == 3:\n                return 1.0\n\n            return super().backoff_strategy()\n    ```\n\n    Returns:\n        The calculated backoff time in seconds, capped by max_backoff_wait.\n    \"\"\"\n    if self.backoff_factor == 0:\n        return 0.0\n\n    # Calculate exponential backoff\n    backoff: float = self.backoff_factor * (2**self.attempts_made)\n\n    # Apply jitter if configured\n    if self.backoff_jitter &gt; 0:\n        backoff *= random.uniform(1 - self.backoff_jitter, 1)\n\n    return min(backoff, self.max_backoff_wait)\n</code></pre>"},{"location":"api/#httpx_retries.Retry.increment","title":"<code>increment()</code>","text":"<p>Return a new Retry instance with the attempt count incremented.</p> Source code in <code>httpx_retries/retry.py</code> <pre><code>def increment(self) -&gt; \"Retry\":\n    \"\"\"Return a new Retry instance with the attempt count incremented.\"\"\"\n    logger.debug(\"increment retry=%s new_attempts_made=%s\", self, self.attempts_made + 1)\n    return self.__class__(\n        total=self.total,\n        max_backoff_wait=self.max_backoff_wait,\n        backoff_factor=self.backoff_factor,\n        respect_retry_after_header=self.respect_retry_after_header,\n        allowed_methods=self.allowed_methods,\n        status_forcelist=self.status_forcelist,\n        retry_on_exceptions=self.retryable_exceptions,\n        backoff_jitter=self.backoff_jitter,\n        attempts_made=self.attempts_made + 1,\n    )\n</code></pre>"},{"location":"api/#httpx_retries.Retry.is_exhausted","title":"<code>is_exhausted()</code>","text":"<p>Check if the retry attempts have been exhausted.</p> Source code in <code>httpx_retries/retry.py</code> <pre><code>def is_exhausted(self) -&gt; bool:\n    \"\"\"Check if the retry attempts have been exhausted.\"\"\"\n    return self.attempts_made &gt;= self.total\n</code></pre>"},{"location":"api/#httpx_retries.Retry.is_retry","title":"<code>is_retry(method, status_code, has_retry_after)</code>","text":"<p>Check if a method and status code are retryable.</p> <p>This functions identically to urllib3's <code>Retry.is_retry</code> method.</p> Source code in <code>httpx_retries/retry.py</code> <pre><code>def is_retry(self, method: str, status_code: int, has_retry_after: bool) -&gt; bool:\n    \"\"\"\n    Check if a method and status code are retryable.\n\n    This functions identically to urllib3's `Retry.is_retry` method.\n    \"\"\"\n    return (\n        self.total &gt; 0\n        and self.is_retryable_method(method)\n        and self.is_retryable_status_code(status_code)\n        and not has_retry_after\n    )\n</code></pre>"},{"location":"api/#httpx_retries.Retry.is_retryable_exception","title":"<code>is_retryable_exception(exception)</code>","text":"<p>Check if an exception is retryable.</p> Source code in <code>httpx_retries/retry.py</code> <pre><code>def is_retryable_exception(self, exception: Exception) -&gt; bool:\n    \"\"\"Check if an exception is retryable.\"\"\"\n    return isinstance(exception, self.retryable_exceptions)\n</code></pre>"},{"location":"api/#httpx_retries.Retry.is_retryable_method","title":"<code>is_retryable_method(method)</code>","text":"<p>Check if a method is retryable.</p> Source code in <code>httpx_retries/retry.py</code> <pre><code>def is_retryable_method(self, method: str) -&gt; bool:\n    \"\"\"Check if a method is retryable.\"\"\"\n    return HTTPMethod(method.upper()) in self.allowed_methods\n</code></pre>"},{"location":"api/#httpx_retries.Retry.is_retryable_status_code","title":"<code>is_retryable_status_code(status_code)</code>","text":"<p>Check if a status code is retryable.</p> Source code in <code>httpx_retries/retry.py</code> <pre><code>def is_retryable_status_code(self, status_code: int) -&gt; bool:\n    \"\"\"Check if a status code is retryable.\"\"\"\n    return status_code in self.status_forcelist\n</code></pre>"},{"location":"api/#httpx_retries.Retry.parse_retry_after","title":"<code>parse_retry_after(retry_after)</code>","text":"<p>Parse the Retry-After header.</p> <p>Parameters:</p> Name Type Description Default <code>retry_after</code> <code>str</code> <p>The Retry-After header value.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The number of seconds to wait before retrying.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the Retry-After header is not a valid number or HTTP date.</p> Source code in <code>httpx_retries/retry.py</code> <pre><code>def parse_retry_after(self, retry_after: str) -&gt; float:\n    \"\"\"\n    Parse the Retry-After header.\n\n    Args:\n        retry_after: The Retry-After header value.\n\n    Returns:\n        The number of seconds to wait before retrying.\n\n    Raises:\n        ValueError: If the Retry-After header is not a valid number or HTTP date.\n    \"\"\"\n    retry_after = retry_after.strip()\n    if retry_after.isdigit():\n        return float(retry_after)\n\n    try:\n        parsed_date = parsedate_to_datetime(retry_after)\n        if parsed_date.tzinfo is None:\n            parsed_date = parsed_date.replace(tzinfo=datetime.timezone.utc)\n\n        diff = (parsed_date - datetime.datetime.now(datetime.timezone.utc)).total_seconds()\n        return max(0.0, diff)\n    except (TypeError, ValueError):\n        raise ValueError(f\"Invalid Retry-After header: {retry_after}\")\n</code></pre>"},{"location":"api/#httpx_retries.Retry.sleep","title":"<code>sleep(response)</code>","text":"<p>Sleep between retry attempts using the calculated duration.</p> <p>This method will respect a server\u2019s <code>Retry-After</code> response header and sleep the duration of the time requested. If that is not present, it will use an exponential backoff. By default, the backoff factor is 0 and this method will return immediately.</p> Source code in <code>httpx_retries/retry.py</code> <pre><code>def sleep(self, response: Union[httpx.Response, Exception]) -&gt; None:\n    \"\"\"\n    Sleep between retry attempts using the calculated duration.\n\n    This method will respect a server\u2019s `Retry-After` response header and sleep the duration\n    of the time requested. If that is not present, it will use an exponential backoff. By default,\n    the backoff factor is 0 and this method will return immediately.\n    \"\"\"\n    time_to_sleep = self._calculate_sleep(response.headers if isinstance(response, httpx.Response) else {})\n    logger.debug(\"sleep seconds=%s\", time_to_sleep)\n    time.sleep(time_to_sleep)\n</code></pre>"},{"location":"behaviour/","title":"Retry Behaviour","text":"<p>If you haven't seen them before, it's not immedately clear what terms like exponential backoff and jitter  mean. And what exactly is a \"retry strategy\", anyway? In this guide we'll break down each of these concepts, show why the defaults have been chosen, and explain how you can configure a custom approach for your retries.</p>"},{"location":"behaviour/#motivation","title":"Motivation","text":"<p>When clients try to perform operations against a remote server, they don't know</p> <ul> <li>If they will succeed (whether or not the operation will transiently fail)</li> <li>If there are other clients also trying to access resources (this is called contention)</li> </ul> <p>By configuring their retry behaviour, they can minimise the time and work needed to complete their (and other clients') operation(s).</p>"},{"location":"behaviour/#definitions","title":"Definitions","text":"<ul> <li>Retry strategy: The choice on how a series of retries is executed.   The wait between each retry is the typical output of a retry strategy.   This may depend on how many retries have already been executed, and if   the server has provided a <code>Retry-After</code> header.</li> <li>Backoff: When there is backoff, a client will wait for increasingly long periods   between retries (it \"backs off\" on retrying). Exponential backoff just means that the   increase in these periods follows an exponential function: typically <code>2 ** number_of_attempts</code>.</li> <li>Jitter: A random factor applied after the backoff is calculated; this serves to   reduce the wait between retries.</li> </ul>"},{"location":"behaviour/#the-default-behaviour","title":"The default behaviour","text":"<p>By default, the Retry object will retry immediately on each attempt (unless a <code>Retry-After</code> header is received), up to <code>Retry.total</code> times. This is a very simple strategy. It's what most users will expect, which is why it's the default.</p> <p>It makes the client more resilient to failures, but it also risks contention on the server, if several clients are retrying at the same time. If there are N clients retrying for the same resource,the work done by server increases proportionally to <code>N^2</code>, as <code>N</code> clients retry in first round, <code>N-1</code> in second and so on.</p>"},{"location":"behaviour/#exponential-backoff","title":"Exponential backoff","text":"<p>Exponential backoff is a common strategy to avoid this. By spreading the retries over a longer period of time, it aims to make sure the server doesn't become overloaded.</p> <p>The formula for exponential backoff looks like</p> <pre><code>backoff_time = backoff_factor * (2 ** attempts_made)\n</code></pre> <p>Info</p> <p>On the first attempt, <code>(exponent ** attempts_made) == 1</code>, and <code>backoff_time</code> will be equal to the <code>backoff_factor</code>.</p> <p>However, if the clients are all retrying at the same time (because they are all following the same exponential wait times), contention is still just as much of an issue, and the amount of work isn't reduced by much (only by the network variance).</p> <p>To solve the problem of grouped retries, we can use jitter to pick a time between some minimum and the exponential backoff time. As this is a random factor, this spreads the retries of the clients evenly, and the server gets a less spiky load. Full jitter just means that the range that is randomly picked from is between <code>0</code> and <code>exponential_backoff_time</code>.</p> <p>This strategy, known as Exponential backoff with full jitter<sup>1</sup>, is optimal when writing a client that might have multiple instances out in the wild.</p> <p>To enable this strategy, just set the backoff_factor parameter for Retry.</p> <p>Tip</p> <p>For production usage in clients, it's highly recommended to enable this behaviour!</p> <p>Note</p> <p>Take some time to read the parameters to Retry, to see what's available to tweak; for example, you can change the amount of <code>jitter</code> applied.</p>"},{"location":"behaviour/#configuring-a-custom-strategy","title":"Configuring a custom strategy","text":"<p>If you want to implement your own retry strategy, you can subclass Retry and override the backoff_strategy method. This method is called for each retry attempt. Take a look at the source for more information on available attributes and how it's used.</p> Example <p>If you wanted to wait 1 second for every third attempt, and otherwise use the default strategy:</p> <pre><code>class CustomRetry(Retry):\n    def backoff_strategy(self) -&gt; float:\n        if self.attempts_made % 3:\n            return 1.0\n\n        return super().backoff_strategy()\n</code></pre> <ol> <li> <p>A great resource for this topic, with some wonderful graphs, can be found on Amazon's architecture blog: Exponential backoff and jitter \u21a9</p> </li> </ol>"},{"location":"contributing/","title":"Contributing","text":"<p>Thank you for being interested in contributing to open source software! There are lots of ways to contribute to the project:</p> <ul> <li>Try it out, and report any bugs or issues that you find</li> <li>Implement new features</li> <li>Review other contributor's pull requests</li> <li>Write documentation</li> <li>Participate in discussions</li> </ul>"},{"location":"contributing/#development","title":"Development","text":"<p>To set up for development:</p> <ol> <li>Fork the repository on GitHub by clicking the \"Fork\" button on the project's GitHub page</li> <li> <p>Clone your fork (replace <code>YOUR-USERNAME</code> with your GitHub username):    <pre><code>git clone https://github.com/YOUR-USERNAME/httpx-retries.git\ncd httpx-retries\n</code></pre></p> </li> <li> <p>Add the original repository as a remote to sync latest changes:    <pre><code>git remote add upstream https://github.com/will-ockmore/httpx-retries.git\n</code></pre></p> </li> <li> <p>Install dependencies:    <pre><code>uv sync\n</code></pre></p> </li> </ol>"},{"location":"contributing/#running-tests","title":"Running Tests","text":"<p>Run the test suite:</p> <pre><code>./scripts/test\n</code></pre> <p>This will run the tests with coverage reporting.</p>"},{"location":"contributing/#code-quality","title":"Code Quality","text":"<p>We use several tools to maintain code quality. Run all checks with:</p> <pre><code>./scripts/check\n</code></pre> <p>This runs:</p> <ul> <li>ruff - For code formatting and linting</li> <li>mypy - For type checking</li> </ul>"},{"location":"contributing/#documentation","title":"Documentation","text":"<p>Documentation is built using MkDocs. To preview locally:</p> <pre><code>mkdocs serve\n</code></pre> <p>Then visit <code>http://127.0.0.1:8000</code> in your browser.</p>"},{"location":"contributing/#pull-requests","title":"Pull Requests","text":"<p>To submit changes:</p> <ol> <li>Fork the repository</li> <li>Create a new branch for your changes</li> <li>Make your changes</li> <li>Run tests and code quality checks</li> <li>Submit a pull request</li> </ol> <p>We aim to review pull requests promptly and provide constructive feedback if needed.</p>"},{"location":"contributing/#releasing","title":"Releasing","text":"<p>This section is for maintainers only.</p> <p>To release a new version:</p> <ol> <li>Update version in <code>pyproject.toml</code> following Semantic versioning (for example: <code>0.2.4</code>)</li> <li>Update <code>CHANGELOG.md</code>, following Keep a Changelog</li> <li>Create a new release on GitHub:</li> <li>Tag version like <code>0.2.4</code></li> <li>Title <code>0.2.4</code></li> <li>Description copied from the changelog</li> <li>The GitHub release will automatically trigger a PyPI publish</li> </ol> <p>If the PyPI publish fails, you can manually publish using: <pre><code>./scripts/publish\n</code></pre></p>"},{"location":"differences_with_other_retry_libraries/","title":"Differences with other retry libraries","text":"<p>HTTPX Retries tries to make configuring retries simple and centralised.</p> <p>Other retry libraries commonly used for retrying requests are general purpose, and this typically means the structure of how you make requests must change if you want to abstract the retry behaviour. This means you've got another level of abstraction to maintain.</p> <p>Tenacity is a popular general-purpose retry library. You wrap a function with a decorator and that function will be retried if certain conditions are met; you configure these conditions at the function definition.</p> <p>If you wanted to retry on connection errors, up to three times, and log a <code>WARNING</code> level log each time, you'd do something like</p> <pre><code>import logging\n\nimport httpx\nfrom tenacity import before_sleep_log, retry, retry_if_exception, stop_after_attempt\n\nlogger = logging.getLogger(__name__)\n\nSOME_HOST: str = \"...\"  # GET requests are known to be flaky on this host.\n\ndef is_some_host_predicate(exc: BaseException) -&gt; bool:\n    return isinstance(exc, httpx.ConnectError) and exc.request.url.host == SOME_HOST\n\n@retry(\n    retry=retry_if_exception(is_some_host_predicate),\n    before_sleep=before_sleep_log(logger, logging.WARNING),\n    stop=stop_after_attempt(3),\n)\nasync def get_from_some_host(client: httpx.AsyncClient, ...):\n    ...\n</code></pre> <p>There are some disadvantages to this approach:</p> <ol> <li>It's less concise. You have to wrap the call to <code>client.get</code> with a function and a decorator, and you have to do this every time you make a request.</li> <li>It incurs a performance cost. The additional function call and any custom predicate logic are not free.</li> <li>It's harder to test. You can use dependency injection with a client-based approach, and test your business logic without retries if desired.</li> <li>Everything is explicit. You can't rely on sensible defaults.</li> </ol> <p>That's why HTTPX Retries was built; you can avoid the additional overhead unless you need it. It's still possible to implement fully custom retry strategies, but the common approach should be simple and configured once.</p>"},{"location":"faq/","title":"FAQs","text":"<p>On this page are some examples of usage and commonly asked questions.</p>"},{"location":"faq/#chaining-transports","title":"Chaining transports","text":"<p>HTTPX Retries is implemented as a custom Transport. It's common to want to add additional custom behaviour (eg. rate-limiting, proxies and more), and it's possible to chain transports to layer in behaviours; the first argument to the RetryTransport constructor is a transport to wrap.</p> <pre><code>with AsyncClient(\n    transport=RetryTransport(\n        RateLimitTransport(\n            AsyncHTTPTransport(),\n            interval=timedelta(seconds=1),\n            count=3,\n        ),\n        retry=Retry(total=5, backoff_factor=0.5),\n    ),\n    timeout=90.0,\n) as client:\n    ...\n</code></pre>"},{"location":"faq/#client-timeout-or-retry-timeout","title":"Client timeout or Retry timeout?","text":"<p>Does the <code>httpx.Client</code> timeout apply to each request made in a series of retries, or to the \"user request\", who wants the result in the next 10s, regardless of how many times the underlying HTTP client needs to try to get it?</p> <p>The timeout passed to <code>httpx.Client</code> applies to each request in a series of retries. If a <code>httpx.TimeoutException</code> is raised and a retry is applicable, the same request, with the same timeout values, will be retried.</p> <p>In the case where retries are bounded by individual (client) timeouts, it is always possible to work out the maximum possible time taken to execute all retries.</p> <p>So if you wanted to add a lower overall retry value than the number of retries multiplied by the client timeout, you could tweak the max_backoff_wait and backoff_factor. Eg.</p> <pre><code>Retry(total=3, max_backoff_wait=5.0, backoff_factor=1, jitter=0)\n</code></pre> <p>would result in a retry-inclusive timeout of <code>15s + 3 * (client_timeout)</code>.</p>"},{"location":"faq/#limits-cert-ssl-http2-parameters-passed-to-the-client-are-not-being-applied","title":"Limits / Cert / SSL / http2 parameters passed to the client are not being applied","text":"<p>This is a limitation of the way transports are applied to clients in HTTPX. If you provide a custom transport, several parameters that can be passed to <code>httpx.Client</code> are ignored. The workaround is to directly provide an instance of httpx.HTTPTransport (or the async variant) which will accept these parameters.</p> <pre><code>with Client(\n    transport=RetryTransport(\n        HTTPTransport(\n            # Pass a transport with these parameters to wrap.\n            http2=True,\n            limits=httpx.Limits(max_connections=100, max_keepalive_connections=100, keepalive_expiry=60),\n            verify=False\n        ),\n        retry=Retry(total=5, backoff_factor=0.5),\n    )\n    # These will do nothing!\n    http2=True,\n    limits=httpx.Limits(max_connections=100, max_keepalive_connections=100, keepalive_expiry=60),\n    verify=False\n) as client:\n    ...\n</code></pre>"},{"location":"logging/","title":"Logging","text":"<p>HTTPX Retries follows Python's standard logging conventions, and combined with httpx's built in logging this means it's easy to see exactly what is happening when retrying requests.</p> <p>The example below demonstrates this.</p> <pre><code>import logging\n\nimport httpx\n\nfrom httpx_retries import Retry, RetryTransport\n\nlogging.basicConfig(\n    format=\"%(levelname)s [%(asctime)s] %(name)s - %(message)s\",\n    datefmt=\"%Y-%m-%d %H:%M:%S\",\n    level=logging.DEBUG\n)\n\ntransport = RetryTransport(retry=Retry(total=3, backoff_factor=0.5))\n\nwith httpx.Client(transport=transport) as client:\n    response = client.get(\"https://httpco.de/429\")\n</code></pre> <p>The result on <code>stdout</code> is:</p> <pre><code>DEBUG [2025-08-23 09:34:21] httpx_retries.transport - handle_request started request=&lt;Request('GET', 'https://httpco.de/429')&gt;\nDEBUG [2025-08-23 09:34:21] httpcore.connection - connect_tcp.started host='httpco.de' port=443 local_address=None timeout=5.0 socket_options=None\nDEBUG [2025-08-23 09:34:21] httpcore.connection - connect_tcp.complete return_value=&lt;httpcore._backends.sync.SyncStream object at 0x1070af9a0&gt;\nDEBUG [2025-08-23 09:34:21] httpcore.connection - start_tls.started ssl_context=&lt;ssl.SSLContext object at 0x1070a0510&gt; server_hostname='httpco.de' timeout=5.0\nDEBUG [2025-08-23 09:34:22] httpcore.connection - start_tls.complete return_value=&lt;httpcore._backends.sync.SyncStream object at 0x1070af970&gt;\nDEBUG [2025-08-23 09:34:22] httpcore.http11 - send_request_headers.started request=&lt;Request [b'GET']&gt;\nDEBUG [2025-08-23 09:34:22] httpcore.http11 - send_request_headers.complete\nDEBUG [2025-08-23 09:34:22] httpcore.http11 - send_request_body.started request=&lt;Request [b'GET']&gt;\nDEBUG [2025-08-23 09:34:22] httpcore.http11 - send_request_body.complete\nDEBUG [2025-08-23 09:34:22] httpcore.http11 - receive_response_headers.started request=&lt;Request [b'GET']&gt;\nDEBUG [2025-08-23 09:34:22] httpcore.http11 - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 23 Aug 2025 08:34:22 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'17'), (b'Connection', b'keep-alive')])\nDEBUG [2025-08-23 09:34:22] httpx_retries.transport - _retry_operation retrying request=&lt;Request('GET', 'https://httpco.de/429')&gt; response=&lt;Response [429 Too Many Requests]&gt; retry=&lt;Retry(total=3, attempts_made=0)&gt;\nDEBUG [2025-08-23 09:34:22] httpx_retries.retry - increment retry=&lt;Retry(total=3, attempts_made=0)&gt; new_attempts_made=1\nDEBUG [2025-08-23 09:34:22] httpx_retries.retry - sleep seconds=0.7751384536885068\nDEBUG [2025-08-23 09:34:22] httpcore.connection - connect_tcp.started host='httpco.de' port=443 local_address=None timeout=5.0 socket_options=None\nDEBUG [2025-08-23 09:34:22] httpcore.connection - connect_tcp.complete return_value=&lt;httpcore._backends.sync.SyncStream object at 0x1070c7c40&gt;\nDEBUG [2025-08-23 09:34:22] httpcore.connection - start_tls.started ssl_context=&lt;ssl.SSLContext object at 0x1070a0510&gt; server_hostname='httpco.de' timeout=5.0\nDEBUG [2025-08-23 09:34:23] httpcore.connection - start_tls.complete return_value=&lt;httpcore._backends.sync.SyncStream object at 0x1070c7c10&gt;\nDEBUG [2025-08-23 09:34:23] httpcore.http11 - send_request_headers.started request=&lt;Request [b'GET']&gt;\nDEBUG [2025-08-23 09:34:23] httpcore.http11 - send_request_headers.complete\nDEBUG [2025-08-23 09:34:23] httpcore.http11 - send_request_body.started request=&lt;Request [b'GET']&gt;\nDEBUG [2025-08-23 09:34:23] httpcore.http11 - send_request_body.complete\nDEBUG [2025-08-23 09:34:23] httpcore.http11 - receive_response_headers.started request=&lt;Request [b'GET']&gt;\nDEBUG [2025-08-23 09:34:23] httpcore.http11 - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 23 Aug 2025 08:34:23 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'17'), (b'Connection', b'keep-alive')])\nDEBUG [2025-08-23 09:34:23] httpx_retries.transport - _retry_operation retrying request=&lt;Request('GET', 'https://httpco.de/429')&gt; response=&lt;Response [429 Too Many Requests]&gt; retry=&lt;Retry(total=3, attempts_made=1)&gt;\nDEBUG [2025-08-23 09:34:23] httpx_retries.retry - increment retry=&lt;Retry(total=3, attempts_made=1)&gt; new_attempts_made=2\nDEBUG [2025-08-23 09:34:23] httpx_retries.retry - sleep seconds=0.979677107701836\nDEBUG [2025-08-23 09:34:24] httpcore.connection - connect_tcp.started host='httpco.de' port=443 local_address=None timeout=5.0 socket_options=None\nDEBUG [2025-08-23 09:34:24] httpcore.connection - connect_tcp.complete return_value=&lt;httpcore._backends.sync.SyncStream object at 0x1070e54c0&gt;\nDEBUG [2025-08-23 09:34:24] httpcore.connection - start_tls.started ssl_context=&lt;ssl.SSLContext object at 0x1070a0510&gt; server_hostname='httpco.de' timeout=5.0\nDEBUG [2025-08-23 09:34:24] httpcore.connection - start_tls.complete return_value=&lt;httpcore._backends.sync.SyncStream object at 0x1070c7940&gt;\nDEBUG [2025-08-23 09:34:24] httpcore.http11 - send_request_headers.started request=&lt;Request [b'GET']&gt;\nDEBUG [2025-08-23 09:34:24] httpcore.http11 - send_request_headers.complete\nDEBUG [2025-08-23 09:34:24] httpcore.http11 - send_request_body.started request=&lt;Request [b'GET']&gt;\nDEBUG [2025-08-23 09:34:24] httpcore.http11 - send_request_body.complete\nDEBUG [2025-08-23 09:34:24] httpcore.http11 - receive_response_headers.started request=&lt;Request [b'GET']&gt;\nDEBUG [2025-08-23 09:34:24] httpcore.http11 - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 23 Aug 2025 08:34:24 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'17'), (b'Connection', b'keep-alive')])\nDEBUG [2025-08-23 09:34:24] httpx_retries.transport - _retry_operation retrying request=&lt;Request('GET', 'https://httpco.de/429')&gt; response=&lt;Response [429 Too Many Requests]&gt; retry=&lt;Retry(total=3, attempts_made=2)&gt;\nDEBUG [2025-08-23 09:34:24] httpx_retries.retry - increment retry=&lt;Retry(total=3, attempts_made=2)&gt; new_attempts_made=3\nDEBUG [2025-08-23 09:34:24] httpx_retries.retry - sleep seconds=2.250136320382409\nDEBUG [2025-08-23 09:34:26] httpcore.connection - connect_tcp.started host='httpco.de' port=443 local_address=None timeout=5.0 socket_options=None\nDEBUG [2025-08-23 09:34:26] httpcore.connection - connect_tcp.complete return_value=&lt;httpcore._backends.sync.SyncStream object at 0x1070e51c0&gt;\nDEBUG [2025-08-23 09:34:26] httpcore.connection - start_tls.started ssl_context=&lt;ssl.SSLContext object at 0x1070a0510&gt; server_hostname='httpco.de' timeout=5.0\nDEBUG [2025-08-23 09:34:27] httpcore.connection - start_tls.complete return_value=&lt;httpcore._backends.sync.SyncStream object at 0x1070e5430&gt;\nDEBUG [2025-08-23 09:34:27] httpcore.http11 - send_request_headers.started request=&lt;Request [b'GET']&gt;\nDEBUG [2025-08-23 09:34:27] httpcore.http11 - send_request_headers.complete\nDEBUG [2025-08-23 09:34:27] httpcore.http11 - send_request_body.started request=&lt;Request [b'GET']&gt;\nDEBUG [2025-08-23 09:34:27] httpcore.http11 - send_request_body.complete\nDEBUG [2025-08-23 09:34:27] httpcore.http11 - receive_response_headers.started request=&lt;Request [b'GET']&gt;\nDEBUG [2025-08-23 09:34:27] httpcore.http11 - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Sat, 23 Aug 2025 08:34:27 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'17'), (b'Connection', b'keep-alive')])\nDEBUG [2025-08-23 09:34:27] httpx_retries.transport - handle_request finished request=&lt;Request('GET', 'https://httpco.de/429')&gt; response=&lt;Response [429 Too Many Requests]&gt;\nINFO [2025-08-23 09:34:27] httpx - HTTP Request: GET https://httpco.de/429 \"HTTP/1.1 429 Too Many Requests\"\nDEBUG [2025-08-23 09:34:27] httpcore.http11 - receive_response_body.started request=&lt;Request [b'GET']&gt;\nDEBUG [2025-08-23 09:34:27] httpcore.http11 - receive_response_body.complete\nDEBUG [2025-08-23 09:34:27] httpcore.http11 - response_closed.started\nDEBUG [2025-08-23 09:34:27] httpcore.http11 - response_closed.complete\n</code></pre>"}]}